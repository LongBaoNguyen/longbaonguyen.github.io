{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1: Introduction to Neural Networks\n",
    "\n",
    "### by Long Nguyen\n",
    "\n",
    "This notebook is supplemental to Lecture 1 of the series \"Introduction to Neural Networks\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist_loader import load_data_wrapper\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The variables training_data, validation_data and test_data above are each a list of (image, label) tuples where image and label are numpy arrays. We won't use the validataion_data for this course. How many images are in training_data? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpack the first image into two variables img1, lb1. What is the shape of each image? What is the shape of each label? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "img1 = training_data[0][0]\n",
    "lbl1 = training_data[0][1]\n",
    "# or equivalently, unpacking the 2-tuple\n",
    "# img1, lbl1 = training_data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the image and its label are rank 2 numpy arrays of shape (781,1) and (10,1), respectively. A label is a one-hot encoding of the digit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the lb1. What digit is this first image of the training set? The 100th image? (Answers: 5 and 1.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[99][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function plot_mnist_digit below draw an MNIST image using the matplotlib library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    \"\"\" Plot a single MNIST image.\"\"\"\n",
    "    image = image.reshape(28,28)\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.matshow(image, cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the function to plot the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.05078125  0.09765625  0.390625    0.4765625   0.02734375\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.12890625  0.58984375  0.8125      0.984375    0.984375    0.984375\n",
      "   0.5703125   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.15625     0.59375\n",
      "   0.953125    0.984375    0.98828125  0.875       0.82421875  0.984375\n",
      "   0.90625     0.15625     0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.05859375  0.59375     0.93359375  0.984375\n",
      "   0.984375    0.984375    0.84375     0.12109375  0.14453125  0.984375\n",
      "   0.984375    0.234375    0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.375       0.984375    0.984375    0.984375\n",
      "   0.984375    0.84765625  0.11328125  0.          0.14453125  0.984375\n",
      "   0.984375    0.234375    0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.70703125  0.984375    0.984375    0.859375\n",
      "   0.65234375  0.1171875   0.          0.          0.30078125  0.984375\n",
      "   0.984375    0.234375    0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.1015625   0.5         0.2265625   0.0859375\n",
      "   0.          0.          0.          0.          0.390625    0.984375\n",
      "   0.984375    0.234375    0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.61328125  0.984375    0.984375\n",
      "   0.234375    0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.4296875   0.47265625  0.4765625   0.47265625  0.7890625   0.984375\n",
      "   0.7578125   0.01171875  0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.0390625   0.20703125  0.69921875\n",
      "   0.98828125  0.98828125  0.99609375  0.98828125  0.98828125  0.890625\n",
      "   0.13671875  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.01953125  0.2109375   0.88671875  0.984375    0.94921875\n",
      "   0.890625    0.6640625   0.9453125   0.984375    0.984375    0.90234375\n",
      "   0.45703125  0.0234375   0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.0234375   0.3046875   0.984375    0.984375    0.48828125  0.23046875\n",
      "   0.          0.0703125   0.8125      0.984375    0.984375    0.984375\n",
      "   0.984375    0.33984375  0.02734375  0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.01953125  0.52734375  0.984375    0.984375    0.703125    0.0625      0.\n",
      "   0.08203125  0.79296875  0.98828125  0.96484375  0.50390625  0.67578125\n",
      "   0.984375    0.984375    0.71875     0.2578125   0.19140625  0.19140625\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.01171875\n",
      "   0.53125     0.984375    0.94140625  0.4140625   0.06640625  0.\n",
      "   0.20703125  0.78125     0.984375    0.84375     0.25390625  0.\n",
      "   0.0546875   0.28125     0.63671875  0.94140625  0.984375    0.984375\n",
      "   0.87109375  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.41015625\n",
      "   0.984375    0.9453125   0.34375     0.0703125   0.28515625  0.6640625\n",
      "   0.953125    0.984375    0.4921875   0.11328125  0.          0.          0.\n",
      "   0.          0.          0.34765625  0.703125    0.703125    0.14453125\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.90234375\n",
      "   0.984375    0.95703125  0.80078125  0.84375     0.984375    0.984375\n",
      "   0.984375    0.484375    0.01171875  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.80859375\n",
      "   0.984375    0.984375    0.984375    0.984375    0.6953125   0.453125\n",
      "   0.140625    0.015625    0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.05078125\n",
      "   0.36328125  0.55859375  0.47265625  0.08984375  0.0234375   0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[5][0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"Plot a list of MNIST images.\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(images))\n",
    "    for j, ax in enumerate(axes):\n",
    "        ax.matshow(images[j][0].reshape(28,28), cmap = plt.cm.binary)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the function above to plot first 10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAAxCAYAAADtL9PQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nowwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126464eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(training_data[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The sigmoid function is define as $$\\sigma(x)=\\frac{1}{1+e^{-x}}.$$ Implement the sigmoid function. Hint: Use np.exp() for the exponential function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector $\\vec{x}\\in\\mathbb{R}^n$, the sigmoid function $\\sigma:\\mathbb{R}\\rightarrow\\mathbb{R}$ can be extended to a vector-valued function $\\sigma:\\mathbb{R}^n\\rightarrow\\mathbb{R}^n$ by applying $\\sigma$ elementwise. \n",
    "That is, if\n",
    "$$\\vec{x}=\\left[ \\begin{array}{cccc}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{m} \n",
    "\\end{array} \\right]$$\n",
    "then\n",
    "$$\\sigma(\\vec{x})=\\left[ \\begin{array}{cccc}\n",
    "\\sigma(x_{1}) \\\\\n",
    "\\sigma(x_{2}) \\\\\n",
    "\\vdots \\\\\n",
    "\\sigma(x_{m}) \n",
    "\\end{array} \\right].$$\n",
    "\n",
    "Similarly, $\\sigma$ can be applied to a $m\\times n$ matrix elementwise. \n",
    "For example, if $$\\vec{x}=\\left[ \\begin{array}{cccc}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \n",
    "\\end{array} \\right]$$\n",
    "then\n",
    "$$\\sigma(\\vec{x})=\\left[ \\begin{array}{cccc}\n",
    "\\sigma(1) \\\\\n",
    "\\sigma(2) \\\\\n",
    "\\sigma(3) \n",
    "\\end{array} \\right]\\approx\\left[ \\begin{array}{cccc}\n",
    "0.73 \\\\\n",
    "0.88 \\\\\n",
    "0.95 \n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73105858],\n",
       "       [ 0.88079708],\n",
       "       [ 0.95257413]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1],[2],[3]])\n",
    "sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define $p_1(\\vec{x})=W_1\\vec{x}+\\vec{b}_1$ and $p_2(\\vec{x})=W_2\\vec{x}+\\vec{b}_2$ for some $W_1, W_2, \\vec{b}_1, \\text{and } \\vec{b}_2.$ \n",
    "\n",
    "Consider the classifier or score function $f=\\sigma\\circ p_2\\circ\\sigma\\circ p_1:\\mathbb{R}^{784}\\rightarrow\\mathbb{R}^{10}.$ This is a two-layer neural network. The score function takes a flattened MNIST image of shape `(784,1)` and output a one-hot vector of shape `(10,1)`. The class with the highest score is the label predicted by the classifier. \n",
    "\n",
    "The training a neural network amounts to producing a set parameters $W_1, W_2, \\vec{b}_1, \\text{and } \\vec{b}_1$ whose score function $f(x; W_1, W_2, \\vec{b}_1, \\vec{b}_2)$ can accurately classify unseen images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the dimensions of $W_1,W_2,b_1,b_2$? Write your answer in this cell using markdown.\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate an example of such a score function, let's load up a set of parameters that has been trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"parameters.npy\", mode=\"rb\") as r:\n",
    "    parameters = np.load(r)\n",
    "    W1, B1, W2, B2 = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the score function with these set of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, W1, W2, B1, B2):\n",
    "    \"\"\"Return the output of the network if ``x`` is input image and\n",
    "    W1, W2, B1 and B2 are the learnable weights. \"\"\"\n",
    "    #Z1 = W1*x+B1  (* represents matrix multiplication)\n",
    "    Z1 = np.dot(W1,x)+B1\n",
    "    #A1 = sigmoid(Z1)\n",
    "    A1 = sigmoid(Z1)\n",
    "    #Z2 = W2*A1+B2 (* represents matrix multiplication)\n",
    "    Z2 = np.dot(W2,A1)+B2\n",
    "    #A2 = sigmoid(Z2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply your score function above to the first two images. Does it classify them correctly?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(f(training_data[5][0],W1,W2,B1,B2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predict function below predict a list of images. It is missing one line of code. Fill in the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, W1, W2, B1, B2):\n",
    "    predictions = []  #empty list\n",
    "    for im in images:\n",
    "        # fill in one line of code here\n",
    "        # this line calls f above with the correct parameters\n",
    "        \n",
    "        predictions.append(np.argmax(a)) # add prediction to predictions list\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call predict above with the first 10 images. Does it classify them correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Find the the first TWO images that are classified incorrectly by the score function above. Write code to do this, do not use trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
